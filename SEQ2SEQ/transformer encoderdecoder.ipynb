{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61b327a2",
   "metadata": {},
   "source": [
    "> Introduction\n",
    "\n",
    "A Transformer is a neural network that processes input sequences by looking at (attending to) all tokens at once instead of reading them one-by-one like RNNs or LSTMs.\n",
    "\n",
    "It uses Self-Attention to decide:\n",
    "\t•\twhich words are important,\n",
    "\t•\thow strongly each word influences another word,\n",
    "\t•\tand in what context the meaning changes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4e3536",
   "metadata": {},
   "source": [
    ">Main components\n",
    "\n",
    "1. Encoder\n",
    "\n",
    "Takes input (like a sentence) and produces context-rich representations.\n",
    "\n",
    "Each encoder block has:\n",
    "\t•\tMulti-Head Self-Attention\n",
    "\t•\tFeed-Forward Network (FFN)\n",
    "\t•\tResidual connections + LayerNorm\n",
    "\n",
    "2. Decoder\n",
    "\n",
    "Generates output tokens one-by-one (like translation, text generation).\n",
    "\n",
    "Each decoder block has:\n",
    "\t•\tMasked Self-Attention\n",
    "\t•\tEncoder-Decoder Attention\n",
    "\t•\tFeed-Forward Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c73b46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
